# Dacon 이미지 색상화 및 손실 부분 복원 AI 경진대회

## Image inpainting

![image](https://github.com/user-attachments/assets/6535a55b-9299-496d-87c6-487aa919e3bf)
###### 출처: Omar Elharrouss, Noor Almaadeed, Somaya Al-Maadeed, Younes Akbari - [Image inpainting: A review]

##### 손상되거나 열화된 이미지를 원래 상태로 되돌리는 기술로, 노이즈 제거, 흐림 현상 개선, 해상도 향상 등을 말하는 것으로 최근 딥러닝의 발전으로 더욱 정교하고 효율적인 복원 기법들이 개발 되고 있다
---

## 사용한 라이브러리 
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Python</title><path d="M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z"/></svg>  
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>PyTorch</title><path d="M12.005 0L4.952 7.053a9.865 9.865 0 000 14.022 9.866 9.866 0 0014.022 0c3.984-3.9 3.986-10.205.085-14.023l-1.744 1.743c2.904 2.905 2.904 7.634 0 10.538s-7.634 2.904-10.538 0-2.904-7.634 0-10.538l4.647-4.646.582-.665zm3.568 3.899a1.327 1.327 0 00-1.327 1.327 1.327 1.327 0 001.327 1.328A1.327 1.327 0 0016.9 5.226 1.327 1.327 0 0015.573 3.9z"/></svg>
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>NumPy</title><path d="M10.315 4.876L6.3048 2.8517l-4.401 2.1965 4.1186 2.0683zm1.8381.9277l4.2045 2.1223-4.3622 2.1906-4.125-2.0718zm5.6153-2.9213l4.3193 2.1658-3.863 1.9402-4.2131-2.1252zm-1.859-.9329L12.021 0 8.1742 1.9193l4.0068 2.0208zm-3.0401 16.7443V24l4.7107-2.3507-.0053-5.3085zm4.7037-4.2057l-.0052-5.2528-4.6985 2.3356v5.2546zm5.6553-.9845v5.327l-4.0178 2.0052-.0029-5.3028zm0-1.8626V6.4214l-4.0253 2.001.0034 5.2633zM11.2062 11.571L8.0333 9.9756v6.895s-3.8804-8.2564-4.2399-8.998c-.0463-.0957-.2371-.2007-.2858-.2262C2.8118 7.2812.773 6.2485.773 6.2485V18.43l2.8204 1.5076v-6.3674s3.8392 7.3775 3.878 7.458c.0389.0807.4245.8582.8362 1.1314.5485.363 2.8992 1.7766 2.8992 1.7766z"/></svg>
<svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>tqdm</title><path d="M12 14.562a2.338 2.338 0 1 1 0-4.677 2.338 2.338 0 0 1 0 4.677zM12 0C5.392 0 .036 5.473.036 12.224c0 5.579 3.659 10.281 8.658 11.746.428.126.87-.162.962-.598l.141-.669c.086-.41-.169-.799-.57-.92-4.039-1.221-6.986-5.037-6.986-9.559 0-5.507 4.37-9.972 9.76-9.972s9.76 4.464 9.76 9.972c0 4.515-2.938 8.325-6.967 9.552-.4.122-.654.511-.567.919l.142.67c.093.437.535.723.963.596 4.986-1.474 8.633-6.169 8.633-11.738C23.964 5.473 18.608 0 12 0zm7.152 12.224c0-4.04-3.202-7.315-7.152-7.315s-7.152 3.275-7.152 7.315c0 3.191 1.999 5.903 4.786 6.902a.79.79 0 0 0 1.037-.582l.042-.199a.772.772 0 0 0-.489-.889c-2.118-.752-3.639-2.809-3.639-5.232 0-3.059 2.424-5.539 5.415-5.539s5.415 2.48 5.415 5.539c0 2.418-1.516 4.472-3.628 5.227a.772.772 0 0 0-.487.89l.042.199a.791.791 0 0 0 1.038.58c2.78-1.003 4.772-3.71 4.772-6.896z"/></svg>

---
## < 모델 설계 전략 >
1. 데이터 증강
2. 기존 Unet 구조의 Decoder 부분에 Sementic Segmentation 적용
3. Masking 처리
4. Unet Encoder에 EfficientNet_b7 추가
5. UNet 구조를 기반으로 Model Tuning => 성능이 가장 높게 나옴

## 성능이 가장 높았던 5번 방법
#### optimizer 비교
![image](https://github.com/user-attachments/assets/747073db-0fa8-45c0-af5f-575ef53b6161)
#### LR 비교 
![image](https://github.com/user-attachments/assets/855d0fc8-2baa-40c0-92bf-b3b26c37ddc8)
#### Loss 비교
![image](https://github.com/user-attachments/assets/de14db90-b0eb-436c-86d2-1d83cfdbcd22)

---

결국에는 BCELoss와 MSELoss를 사용한 기본 구조가 가장 높고 Optimizer 변경을 한 것이 큰 성능 향상이 있었다

학습LOSS 그래프 시각화 - 중간에 발산하지만 다시 수렴하는 결과값을 볼 수 있음
![image](https://github.com/user-attachments/assets/487eccdf-5776-4d15-96bc-e7c250fb4577)

## 복원 결과 Test -> Prediction

![TEST_002](https://github.com/user-attachments/assets/716367c2-60c2-4054-ad3c-53e179c445ac)
![TEST_002](https://github.com/user-attachments/assets/18fe69ad-5088-4a74-b8b7-a277fa7a2f7f)

